/*! @page quick_guide Quick Guide

@section qg_intro_sec Introduction

So let us take a moment to understand the hierarchical structure that MANAK
uses. When manak.hpp is included in the project it also included the master 
benchmarking suit which registers all the benchmarking cases. This master suit 
is a special case of a benchmarking suit which may have more test suits or 
cases as its children. On the other hand benchmarking case is a leaf node in 
this tree(or so we assume util template benchmarks come into picture).
Each benchmark case is charectorized by a function which is ultimately timed. 
This hierarchical structure helps us to run specific benchmarks. Now that we know
the hierarchical structure we can introduce the concept of library into this
picture. Libaries in MANAK are considered groups of benchmarking cases that are 
compared against each other. So now we can say that a benchmark case is 
characterized by function and a library. The benchmark cases having same name 
and different library are compared against each other in the output. Remember 
benchmarking suits maintain their own namespace so benchmarking cases having 
same name and different suit won't be compared. 

So now we can start benchmarking. The benchmark cases and suits in Manak
can be registred either manually or automatically. But in this quick guide we 
are only going to consider auto registration. For more information on manual 
registration check out @ref man_reg

Before we start registration of cases let us understand the timing features
of MANAK. The time is measured in microseconds. The function runs for given
number of iterations and the average of all iterations is taken as the final 
result. When number of iterations is not given the default is used(Which is 10
if not set otherwise). The default can be changed by setting 
'MANAK_DEFAULT_ITERATIONS' to the desired value.

MANAK offers 2 benchmarking modules. For more information on benchmarking modules
check out @ref set_env_smt.

@section qg_sbm Simple Benchmarking Module

Simple benchmarking module can be used when only one library is compared against
itself with time. For detailed information on Simple Benchmark Module see 
@ref s_mod

To set the module to simple benchmark module, set
'MANAK_SIMPLE_BENCHMARK_MODULE' to the name of the module.
           
@code
#define MANAK_SIMPLE_BENCHMARK_MODULE name
@endcode

This will by default add all the cases to library by the name "base_library".
This name can be changed by setting MANAK_BASE_LIBRARY_NAME to desired name. 

So let us register our first benchmark case to the master suit. 

@code
#include <iostream>

#define MANAK_SIMPLE_BENCHMARK_MODULE bench
#define MANAK_AUTO_BENCHMARK_MAIN

#include <manak/manak.hpp>

MANAK_AUTO_BENCHMARK_CASE(ForLoops)
{
  for(size_t i = 0;i < 1000;i++);
}
@endcode

Thats it! This will automatically registers the case in master suit and the 
MANAK_AUTO_BENCHMARK_MAIN define will generate the main for you. Manak uses C++11
features so don't forget to add option '-std=c++11' to g++ or clang. By default 
the output will be saved to file 'benchmark_stat.txt' and will look like -

@code
######################################################################
#  Manak C++ Benchmarking Library                                    #
#  Version 1.0.0                                                     #
#  Created at Nov 13 16:21:39 2014                                   #
######################################################################

       Case Name              base_library        

ForLoops                      3.3  
@endcode

To change the default output file set 'MANAK_DEFAULT_OUT_FILENAME' to desired 
value. Check out @ref set_env_soof for more options. While running the benchmark 
case all the ouput to standard output will be redirected by default to the file 
'benchmark_log.txt'. To chnage the default set 'MANAK_REDIRECTION_FILENAME' to 
desired value. For more options about redirection check @ref set_env_sro.

If you want to generate the main for yourselves check @ref set_env_mcmf

Sometimes the code to be measured requires another code to be executed before or 
after, sort of like set up and tear down. To measure such a code 'Measure' macro
can be used. For example - 

@code
MANAK_AUTO_BENCHMARK_CASE(B1)
{
  Set up code;
  
  Measure
  (
    Code to be measured;
  )
  
  Tear down;
}
@endcode

This way only the run time of code inside the 'Measure' block will be measured.
There can be more than one 'Measure' blocks inside a function. The total time 
will be considered as the sum of all such 'Measure' blocks inside the function.

@code
MANAK_AUTO_BENCHMARK_CASE(B1)
{
  Set up code;
  
  Measure
  (
    Code to be measured;
  )
  
  Tear down;
}
@endcode

For more time related features check out @ref all_time

For providing the number of iteration use 'MANAK_AUTO_BENCHMARK_CASE_I'.

@code
MANAK_AUTO_BENCHMARK_CASE_I(B1, 100)
{
  Code;
}
@endcode

For more auto benchmark options check @ref auto_reg

To register a function as benchmark case -

@code
int fun()
{}

MANAK_ADD_BENCHMARK(MANAK_BENCHMARK_CASE(B1, fun));
@endcode

Remember 'Measure' block can also be used inside manually generated functions.

Functions with parameters can be used as template benchmark function.
For example - 

@code

int fun(int a, int b)
{
  Code;
}

MANAK_ADD_BENCHMARK(MANAK_CREATE_BENCHMARK_WITH_TEMPLATE(B1, fun)->AddArgs(0,0)->AddArgs(1,0)...);
@endcode

Here we can see that benchmark case contains 2 benchmark sub-cases corresponding 
to each paramter set. These can be considered as paremeterized benchmark cases. 
'MANAK_CREATE_BENCHMARK_WITH_TEMPLATE' generates a parametrized benchmark case
which can hold any number of benchmark sub-cases. Function 'AddArgs' adds a new
benchmark sub-case to the parametrized benchmark case with given parameters.
Sometimes number of parameter sets is too large and 'AddArgs' becomes inconvenient.
In such cases 'AddCustomArgs' can be used.

@code
#include <iostream>
#include <tuple>
#include <list>

#define MANAK_SIMPLE_BENCHMARK_MODULE lib
#define MANAK_AUTO_BENCHMARK_MAIN

#include <manak/manak.hpp>

using namespace std;

int fun(int a, int b)
{
  Code;
}

list<tuple<int, int>> get_args()
{
  list<tuple<int, int>> out;
  for(size_t i = 0;i < 100;i++)
    out.emplace_back(i, i);
  return out;
}

MANAK_ADD_BENCHMARK(MANAK_CREATE_BENCHMARK_WITH_TEMPLATE(B1, fun)->AddCustomArgs(get_args));
@endcode 

The function passed to 'AddCustomArgs' must return list of tuples. These returned
tuples will be unfolded and passed to the parametrized benchmark case one by one.
For more advance parametrized benchmark options check ... .

The auto test registration registers the case to the current suit(which happens 
to be the master suit in global space). 'MANAK_AUTO_BENCHMARK_SUITE' registers
a new suite under the current suit and sets the newly created suite as the 
current suite. 

@code
MANAK_AUTO_BENCHMARK_SUITE(Suite1);

MANAK_AUTO_BENCHMARK_CASE(B1)
{
  Code;
}
@endcode

Here B1 will be registered under Suite1 and Suite1 will be registered under the 
master suite. 'MANAK_AUTO_BENCHMARK_SUITE_END()' can be used to set current suite 
to the parent. For example -

@code
MANAK_AUTO_BENCHMARK_SUITE(Suite1);

MANAK_AUTO_BENCHMARK_SUITE(Suite2);

MANAK_AUTO_BENCHMARK_CASE(B1)
{
  Code;
}

MANAK_AUTO_BENCHMARK_SUITE_END();

MANAK_AUTO_BENCHMARK_CASE(B1)
{
  Code;
}
@endcode

In this example B1 will be registered under Suite2 where as B2 will be registered 
under Suite1. And in the same way Suite2 will be registered under Suite1 and 
Suite1 under master. This hierarchical structure helps in running specific 
benchmarks at a time. For more information on auto registration see @ref auto_reg.

@section qg_bm Benchmaking Module

This module is useful when the code also needs to be compared against other 
libraries. For detailed information on this module see @ref n_mod

A simple cases registration in this module will look like - 

@code
#include <iostream>

#define MANAK_BENCHMARK_MODULE bench
#define MANAK_AUTO_BENCHMARK_MAIN

MANAK_AUTO_BENCHMARK_CASE(B1, lib1)
{
  Code;
}
MANAK_AUTO_BENCHMARK_CASE(B1, lib2)
{
  Code;
}
@endcode

The output will compare the lib1 and lib2 with results of B1.

All the macros used in 'MANAK_SIMPLE_BENCHMARK_MODULE' are still valid with one
extra parameter. 

@code
MANAK_AUTO_BENCHMARK_CASE_I(B1, lib1, 10)
{
  Code;
}######################################################################
#  Manak C++ Benchmarking Library                                    #
#  Version master.0.0                                                #
#  Created at Nov 13 22:41:53 2014                                   #
######################################################################

       Case Name              base_library        

ForLoop                       3.2[3:4]            

int fun()
{}

MANAK_ADD_BENCHMARK(MANAK_BENCHMARK_CASE(B1, lib2, fun));

int fun2(int a, int b)
{
  Code;
}

list<tuple<int, int>> get_args()
{
  list<tuple<int, int>> out;
  for(size_t i = 0;i < 100;i++)
    out.emplace_back(i, i);
  return out;
}

MANAK_ADD_BENCHMARK(MANAK_CREATE_BENCHMARK_WITH_TEMPLATE(B2, lib2, fun2)->AddCustomArgs(get_args));
@endcode

See @ref auto_reg for more information on auto registration.

@section qg_comp Manak Comparison Framework

In 'MANAK_BENCHMARK_MODULE' benchmark cases having same name(and same suite) 
and different library will automatically get compared against in the output.
For example for code 

@code
#include <iostream>

#define MANAK_BENCHMARK_MODULE bench
#define MANAK_AUTO_BENCHMARK_MAIN

#include <manak/manak.hpp>

MANAK_AUTO_BENCHMARK_CASE(ForLoops, lib1)
{
  for(size_t i = 0;i < 1000;i++);
}

MANAK_AUTO_BENCHMARK_CASE(ForLoops, lib2)
{
  for(size_t i = 0;i < 10000;i++);
}
@endcode

The output will look like -

@code
######################################################################
#  Manak C++ Benchmarking Library                                    #
#  Version 1.0.0                                                     #
#  Created at Nov 13 16:15:39 2014                                   #
######################################################################

       Case Name              lib1                lib2                

ForLoops                      3.4                 31.8
@endcode

Manak also offers saving these results for comparison. This comparison type is 
available for both simple and normal Pass argument '-s <filename>'
to executable for saving the results for comparison. This specially saved file 
can be loaded for comparison with command line arguments '-c <filename>'. Let us 
assume 'bench' is the executable name then -

@code
bench -s saved.txt
bench -c saved.txt
@endcode

The output of the second run will be saved to 'benchmark_stat.txt'.
The output will sort of look like - 

@code
######################################################################
#  Manak C++ Benchmarking Library                                    #
#  Version 1.0.0                                                     #
#  Created at Nov 13 17:03:46 2014                                   #
######################################################################

       Case Name              lib1                lib2                

ForLoops                      +42.4(3.2)          -0.1(31.6)
@endcode

The values in bracket are the values loaded for comparison. Loaded values are 
also compared with the current values with tolerance. The result of the comparison
is shown with a sign in front of the current value. No sign will imply equivalent 
runs. The default tolerance is 10 which can be changed by setting 
'MANAK_DEFAULT_TOLERANCE' to desired value. Also tolerance for each test can be 
set by using 'MANAK_AUTO_BENCHMARK_CASE_T'

@code
MANAK_AUTO_BENCHMARK_CASE_T(ForLoops, lib1, 50)
{
  Code;
}
@endcode

The default measure of tolerance is in microseconds. Pass command line argument 
'-h' for more help.

@section qg_rsc Running Specific Cases

Manak provides support for running speciic benchmark cases of all. This can be 
achieved by passing argument '-r <regex>' to the executable. All the benchmark 
matching the regex will run. 

How to write a regex:
 - To access the child of any suite "/" token can be used. 
 - If an entire suite matches the regex, all the children of that suite will run.
 - All type of regex expressions are supported between "/" tokens.
 
Example -
To run a suite named 'B1' under master suite 
@code
bench -r B1
@endcode

To run a suite named 'B2' under B1

@code
bench -r B1/B2
@endcode

To run all children of suite B1(child of master) starting with "Bench"

@code
bench -r B1/Bench.*
@endcode

*/
